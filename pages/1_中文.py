import streamlit as st
import boto3
from llama_index.core import ( 
    VectorStoreIndex,
    SimpleDirectoryReader,
    Document,
    StorageContext,
    load_index_from_storage
)
from llama_index.core.settings import Settings
from llama_index.llms.bedrock import Bedrock
from llama_index.embeddings.bedrock import BedrockEmbedding, Models

# Clear Chat History fuction
def clear_screen():
    for key in st.session_state.keys():
        del st.session_state[key]
    st.session_state.messages = [{"role": "assistant", "content": "ä½ å¥½ï¼Œçƒ¹é¥ªå¤§å¸ˆï¼é—®æˆ‘æœ‰å…³å°è´©æ‘Šä½æŠ•æ ‡çš„é—®é¢˜!"}]

# Function to set the question when a sample question is clicked
def set_question(question):
    st.session_state.question = question
    
st.set_page_config(page_title="å°è´©äººå·¥æ™ºèƒ½åŠ©æ‰‹ ğŸ¤–ğŸ’¬", layout="centered", initial_sidebar_state="auto", menu_items=None)
st.sidebar.success("é€‰æ‹©ä¸Šé¢çš„è¯­è¨€")
with st.sidebar.expander("è¿‡å»çš„èŠå¤©è®°å½•", expanded=True):
        st.markdown("""
        `[ 22 Dec 2024 ]`
        ä½ : éå¸¸æ„Ÿè°¢ä½ çš„å¸®åŠ©! ğŸ‘  
        """)

col1, col2 = st.columns([3,1])
with col2:
    if st.button('æ¸…é™¤èŠå¤©è®°å½•'):
        clear_screen()

st.image("./images/logo.png")
gradient_text_html = """
    <style>
    .gradient-text {
        font-weight: bold;
        background: -webkit-linear-gradient(left, green, lightblue);
        background: linear-gradient(to right, green, lightblue);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        display: inline;
        font-size: 3em;
    }
    </style>
    <div class="gradient-text">å°è´©äººå·¥æ™ºèƒ½åŠ©æ‰‹ </div>
    """
st.markdown(gradient_text_html, unsafe_allow_html=True)

st.markdown("### æ ·é¢˜")

# Custom CSS for the buttons
st.markdown("""
<style>
    .stButton > button {
        width: 100%;
        height: 75px;
        white-space: normal;
        word-wrap: break-word;
    }
</style>
""", unsafe_allow_html=True)

# Create three columns for the buttons
col1, col2, col3 = st.columns(3)

with col1:
    if st.button("Maxwell ç†Ÿé£Ÿä¸­å¿ƒ ç†Ÿé£Ÿæ‘Šä½çš„æœ€é«˜å‡ºä»·æ˜¯å¤šå°‘?"):
        set_question("Maxwell ç†Ÿé£Ÿä¸­å¿ƒ ç†Ÿé£Ÿæ‘Šä½çš„æœ€é«˜å‡ºä»·æ˜¯å¤šå°‘?")
with col2:
    if st.button("æˆ‘å¦‚ä½•ç”³è¯·æˆä¸ºå°è´©ï¼Ÿ"):
        set_question("æˆ‘å¦‚ä½•ç”³è¯·æˆä¸ºå°è´©ï¼Ÿ")
with col3:
    if st.button("å¦‚æœæˆ‘çš„é¢„ç®—æ˜¯$500ï¼Œæˆ‘å¯ä»¥æ ‡åˆ°å“ªä¸€ä¸ªå°è´©ä¸­å¿ƒçš„æ‘Šä½?"):
        set_question("å¦‚æœæˆ‘çš„é¢„ç®—æ˜¯$500ï¼Œæˆ‘å¯ä»¥æ ‡åˆ°å“ªä¸€ä¸ªå°è´©ä¸­å¿ƒçš„æ‘Šä½?")

# Setup Bedrock
region='us-east-1'

bedrock_runtime = boto3.client(
    service_name='bedrock-runtime',
    region_name=region,
    aws_access_key_id=st.secrets["AWS_ACCESS_ID"],
    aws_secret_access_key=st.secrets["AWS_ACCESS_KEY"]
)

llm = Bedrock(client=bedrock_runtime, model = "anthropic.claude-3-5-sonnet-20240620-v1:0", system_prompt="""ä½ æ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œæ—¨åœ¨å¸®åŠ©è§£å†³ä¸å°è´©ç›¸å…³çš„æŸ¥è¯¢ã€‚æ‚¨çš„çŸ¥è¯†ä¸»è¦æ¥è‡ªä¸¤ä¸ªæ¥æºï¼š

    1. åŒ…å«å°è´©æ‘Šä½æŠ•æ ‡æ•°æ®çš„ CSV æ–‡ä»¶ã€‚è¿™åŒ…æ‹¬å°è´©ä¸­å¿ƒåç§°ã€äº¤æ˜“ç±»å‹å’Œå‡ºä»·é‡‘é¢ç­‰ä¿¡æ¯ã€‚
    2. æä¾›æœ‰å…³å¦‚ä½•æˆä¸ºå°è´©çš„ä¿¡æ¯çš„ PDF æ–‡æ¡£ã€‚

    å›ç­”é—®é¢˜æ—¶ï¼š
    1. æœ‰å…³æŠ•æ ‡æˆ–æŠ•æ ‡é‡‘é¢çš„æŸ¥è¯¢ï¼Œè¯·ä»…å‚è€ƒ CSV æ–‡ä»¶ã€‚
    2. æœ‰å…³æˆä¸ºå°è´©çš„æµç¨‹ã€æ³•è§„æˆ–æœ‰å…³å°è´©æ–‡åŒ–çš„ä¸€èˆ¬ä¿¡æ¯çš„é—®é¢˜ï¼Œè¯·ä½¿ç”¨ PDF æ–‡æ¡£ä¸­çš„ä¿¡æ¯ã€‚
    3. è®©æ‚¨çš„å›ç­”ç®€æ´ã€çœŸå®ã€‚
    4. å¦‚æœä½¿ç”¨è¿™äº›æ¥æºéƒ½æ— æ³•å›ç­”é—®é¢˜ï¼Œè¯·è¯´æ˜â€œæˆ‘å½“å‰çš„æ•°æ®ä¸­æ²¡æœ‰è¯¥ä¿¡æ¯â€ã€‚
    5. è¯·å‹¿å‘æ˜ã€å‡è®¾æˆ–å¹»æƒ³è¿™äº›æ–‡æ¡£ä¸­æä¾›çš„ä¿¡æ¯ä¹‹å¤–çš„ä»»ä½•ä¿¡æ¯ã€‚
              
    æ ¹æ®é¢„ç®—æä¾›å»ºè®®æ—¶:
    1. å¦‚æœç”¨æˆ·è¯¢é—®ä»–ä»¬å¯ä»¥æ ¹æ®é¢„ç®—ç«æ ‡å“ªä¸ªå°è´©ä¸­å¿ƒï¼ˆä¾‹å¦‚ï¼Œâ€œå¦‚æœæˆ‘çš„é¢„ç®—æ˜¯$500ï¼Œæˆ‘å¯ä»¥ç«æ ‡å“ªä¸ªå°è´©ä¸­å¿ƒï¼Ÿâ€ï¼‰ï¼Œè¯·ä½¿ç”¨ CSV æ–‡ä»¶æŸ¥æ‰¾åˆé€‚çš„é€‰é¡¹ã€‚

    æ‚¨çš„èŒè´£æ˜¯ååŠ©æ½œåœ¨å’Œç°æœ‰çš„å°è´©æä¾›æœ‰å…³å‡ºä»·ã€æˆä¸ºå°è´©çš„æµç¨‹çš„å‡†ç¡®ä¿¡æ¯ï¼Œå¹¶ä»…æ ¹æ®æ‰€æä¾›çš„æ–‡ä»¶åœ¨éœ€è¦æ—¶æä¾›å»ºè®®.""")

embed_model = BedrockEmbedding(client=bedrock_runtime, model = "amazon.titan-embed-text-v1")

Settings.llm = llm
Settings.embed_model = embed_model

@st.cache_resource(show_spinner=False)
def load_data():
  with st.spinner(
    text="å¯åŠ¨äººå·¥æ™ºèƒ½å¼•æ“ã€‚å¯èƒ½è¿˜è¦ç­‰ä¸€ä¸‹..."):
    # load the documents and create the index
    documents = SimpleDirectoryReader(input_dir="data", recursive=True).load_data()
    index = VectorStoreIndex.from_documents(documents)
    return index

# Create Index
index=load_data()

# Initialize the chat messages history        
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "ä½ å¥½ï¼Œçƒ¹é¥ªå¤§å¸ˆï¼é—®æˆ‘æœ‰å…³å°è´©æ‘Šä½æŠ•æ ‡çš„é—®é¢˜!"}
    ]

# Initialize the chat engine
if "chat_engine" not in st.session_state: 
        st.session_state.chat_engine = index.as_chat_engine(chat_mode="condense_question", verbose=True)

# Always show the chat input
user_input = st.chat_input("é—®æˆ‘é—®é¢˜")

# Display the prior chat messages
for message in st.session_state.messages: 
    with st.chat_message(message["role"]):
        st.write(message["content"].replace("$", "\$"))

# Process new input (either from sample question or user input)
new_input = None
if "question" in st.session_state:
    new_input = st.session_state.question
    del st.session_state.question
elif user_input:
    new_input = user_input

if new_input:
    # Add user message to chat history
    st.session_state.messages.append({"role": "user", "content": new_input})
   
    # Display user message
    with st.chat_message("user"):
        st.markdown(new_input)

    # Generate and display assistant response
    with st.chat_message("assistant"):
        with st.spinner("è¯·ç»™æˆ‘ä¸€åˆ†é’Ÿï¼Œè®©æˆ‘æƒ³æƒ³..."):
            response = st.session_state.chat_engine.chat(new_input)
            st.markdown(response.response.replace("$", "\$"))

            # Add assistant response to chat history
            st.session_state.messages.append({"role": "assistant", "content": response.response})

            # Add feedback buttons
            col1, col2, col3 = st.columns(3)
            with col1:
                if st.button("ğŸ‘ æœ‰å¸®åŠ©"):
                    st.success("Thank you for your feedback!")
                    # Log the positive feedback here
            with col2:
                if st.button("ğŸ‘ æ²¡æœ‰å¸®åŠ©"):
                    st.error("We're sorry to hear that. We'll work on improving.")
                    # Log the negative feedback here
            with col3:
                if st.button("ğŸ¤” ä¸æ¸…æ¥š"):
                    st.warning("We'll try to make our responses clearer.")
                    # Log the feedback about clarity here
